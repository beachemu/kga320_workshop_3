---
title: "Observations I"
author: "KGA320: Our Changing Climate"
date: "Semester 2 2024"
output: 
  learnr::tutorial:
    theme: lumen
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(ggplot2)
library(rlang)

source_files_directory <- './data'
setwd('.')

work_env <<- new.env(parent = emptyenv())

exercise.checker <- function(user_code, ...) {
  # Run the submitted code
  eval(parse(text = user_code))
  list2env(as.list(environment(), all.names = TRUE), envir = work_env)
  return(list(message = "Code executed", correct = TRUE))
}

tutorial_options(exercise.checker = exercise.checker)

```




## Introduction: R and Data Wrangling

Hey there, **KGA320**! Today, we're diving into a tool that's revolutionised geography and beyond for the past 30 years: **R**. While creating statistical analyses in a coding language might seem daunting, you'll soon see how R makes our lives easier and more versatile. In fact, we wrote this entire workshop using R!

### What is R?

[R](https://www.r-project.org/about.html) is a programming language built especially for statistics. It's become so ubiquitous that you'd be hard-pressed to find a statistician or scientist who doesn't use it. Why? Because it makes our analysis repeatable. Want someone to check your work? Just send them your code and dataset. Simple!

Usually, R users interact with the language through [RStudio](https://posit.co/download/rstudio-desktop/). For simplicity's sake, we're hosting an instance on R over pages for each workshop. You'll see neat little coding blocks like this:

```{r example, exercise=TRUE, exercise.eval=TRUE}
# This simple line of code prints out "Hello World!"
print("Hello World!")
```

```{r example-hint}
print("Hello World!")
```

> üí° **Pro tip:** Click the "Hint" button if you're ever stuck, or click "Start Over" to start from scratch.

> üî• **Important:** You cannot save your work on this webpage. If you create something you want to keep, save it to your computer!

Now, you might be wondering...

> ü§î **Why aren't we using RStudio this semester?**
>
> -   We want to ensure everyone has the same experience with R, regardless of their computer setup.
> -   Different laptops and operating systems can introduce complications that might distract from learning to code.
> -   Our goal is to keep things simple and focus on the joy of coding!

Don't worry, though - if you're curious about RStudio:

1.  UTAS computers have RStudio installed.
2.  We've shared the source code for these workshops on MyLo.
3.  Feel free to explore RStudio in your own time!

### Data Wrangling

Before we can make pretty graphs, we need data! Climate scientists have a wealth of information at their fingertips, from paleoclimatology to modern measurements. For this workshop, we'll focus on drought measures and historical daily temperature data for the Barossa Valley, northeast of Adelaide.

**Data wrangling** is the process of preparing our various data sources for analysis. In creating this workshop, Ben has already done some wrangling to get this data into a format you will probably be familiar with: a CSV file. This pre-wrangling saves us some time, but it's still crucial to familiarise yourself with the data:

> üí° **Pro Tip:** Download the CSV files from the MyLo workshop page and open them in Excel or another spreadsheet app. This allows you to:
>
> -   Scroll through the file to spot missing data or obvious problems.
> -   Check headers for available variables and units of measurement.
> -   Get a general feel for your dataset.

Viewing our data in Excel is convenient for these initial checks. Once you're satisfied with your data overview, it's time to load it into R:

```{r load_data, exercise=TRUE}
 # Load Barossa historical climate data
barossa_data <- read.csv("data/barossa_1951-2014.csv")
```

Let's break this down:

-   `read.csv()` is a **function** that reads our CSV files.
-   We're saving the data into a variable `barossa_data` using `<-`.
-   These variables are now containers we can access throughout our session.

To check if it worked, we can use the `str()` function:

```{r check_load, exercise=TRUE, exercise.setup="load_data"}
str(barossa_data) # Show the structure of the data frame.
```

Using `str(barossa_data)`, we have created an output showing that `barossa_data` is a `data.frame`, basically a table, which has collected 23360 observations over 4 variables. We see each of therse variables listed with a type, and some example values. When we are making calculations, we always want to be working with variables classed as `num`, R has recognised them as numbers that can be manipulated.

It can be hard to guess what a variable is based just on it's name, usually we pair a data set with a dictionary or documentation to explain what a variable is measuring, the units of measurement or type of variable, and any context we might need. For example, here's the data dictionary for `barossa_data`:

-   `time` (**unit**: date, **type**: `char`): Date of measurement for weather data, stored as a string of format "YYYY-MM-DD".

-   `tasmin` (**unit**: ¬∞C, **type**: `num`): Daily minimum near-surface air temperature.

-   `tasmax` (**unit**: ¬∞C, **type**: `num`): Daily maximum near-surface air temperature.

-   `pr` (**unit**: mm, **type**: `num`): Daily precipitation.

### We have wrangled, now what?

#### Basic Inferential Statistics

Before diving into R's statistical prowess, let's refresh our memory on some key concepts. We'll use the example dataset $[1, 2, 3, 5]$ to illustrate:

-   **Mean:** The average. Sum everything up and divide by the number of items. $\text{Mean} = \frac{1 + 2 + 3 + 5}{4} = 2.75$.
-   **Median:** The middle value when data is sorted. With an even number of items, we average the two middle values. $\text{Median} = \frac{2 + 3}{2} = 2.5$.
-   **Standard Deviation:** A measure of spread. It's a bit trickier:
    1.  Calculate the difference of each value from the mean and square it: $[3.0625, 0.5625, 0.0625, 5.0625]$.
    2.  Find the average of these squares (the variance): $\frac{3.0625 + 0.5625 + 0.0625 + 5.0625}{4} = 2.1875$.
    3.  Take the square root of the variance: $\sqrt{2.1875} \approx 1.48$.

Whew! That's a lot of work by hand. It may have been a while since you've seen these definitions.

The good news? R makes these calculations a breeze. Let's find the mean, median, and standard deviation of the `tasmax` column in our `historical_data`:

```{r inferential_stats, exercise=TRUE, exercise.setup="load_data"}
# Calculate statistics for tasmax
mean_tasmax <- mean(barossa_data$tasmax, na.rm = TRUE)
median_tasmax <- median(barossa_data$tasmax, na.rm = TRUE)
sd_tasmax <- sd(barossa_data$tasmax, na.rm = TRUE)

# Print results
cat("Mean:", mean_tasmax, "\n")
cat("Median:", median_tasmax, "\n")
cat("Standard Deviation:", sd_tasmax, "\n")
```

The function `cat` merges it's inputs into a single **string** (words and characters, `"Mean:"` is a string in the above code for example), and sends it to the output. `"\n"` is a special command in a string that we use to create a new line. Also, note the `na.rm = TRUE` argument. This tells R to ignore missing values (NAs) in our data. Now is a good time to start playing with variables. See if you can modify the code above to find the descriptive statistics for precipitation, `pr`.

### Deep breath

Let's take a quick breather. If you're new to programming, that was a lot to take in. Pat yourself on the back for making it this far!

We've introduced many new terms and techniques. If any **bolded terms** are unfamiliar, jot them down with their definitions. Keep this list handy for revision - we'll use these words frequently in upcoming workshops.

#### Why are we so strict with the language so far?

We want to ensure we all speak the same language over the following few workshops, so learning the key terms will be essential. Clear communication is crucial in a field with constant streams of new information. When we all use the same terminology, it's easier to:

1.  Understand each other's work.
2.  Build upon existing knowledge.
3.  Avoid misinterpretations that could lead to errors.

So, while we might not use much slang, we'll use plenty of scientific lingo. Think of it as learning a new language - the language of data science!

#### Data Visualisation with ggplot2

Now for the fun part: visualisation! We'll use **ggplot**, a powerful plotting library built as a part of the [tidyverse](https://www.tidyverse.org/). First, let's load it:

```{r call_libraries, exercise=TRUE, exercise.setup="inferential_stats"}
library(ggplot2)
```

ggplot uses the "grammar of graphics" - we build plots layer by layer. Here's a box plot of Barossa Valley's maximum temperature using the descriptive statistics we calculated previously.

First, we'll create a summary data frame:

```{r summary, exercise=TRUE, exercise.setup="call_libraries"}
summary_data <- data.frame(
  ymin = mean_tasmax - 1.5 * sd_tasmax,
  lower = mean_tasmax - sd_tasmax,
  y = mean_tasmax,
  upper = mean_tasmax + sd_tasmax,
  ymax = mean_tasmax + 1.5 * sd_tasmax
)
```

> ‚ùì **Hint:** Remember earlier we described data frames as essentially R's version of tables. Here we are collecting the 5 variables `ymin, lower, y, upper, ymax`, as variables that are stored in `summary_data`. Remember, we can use `str(summary_data)` to see what this looks like.

This data frame contains the key values for our boxplot: the minimum, lower quartile, median, upper quartile, and maximum. We've used our calculated mean and standard deviation from earlier to calculate these values.

Now, let's create the boxplot:

```{r plotting, exercise=TRUE, exercise.setup="summary"}
# Create a simplified boxplot
ggplot(summary_data, aes(x = "Max Temp", y = y)) +
  geom_boxplot(aes(ymin = ymin, lower = lower, middle = y, upper = upper, ymax = ymax),
               stat = "identity", fill = "lightblue", width = 0.5) +
  geom_point(aes(y = median_tasmax), color = "red", size = 3) +
  ggtitle("Distribution of Maximum Temperatures in Barossa Valley (1951-2014)") +
  ylab("Maximum Temperature (¬∞C)") +
  xlab("") +
  theme_minimal()
```

This might look dense, but there's a logic to how the graph is built. Let's break it down using the grammar of graphics:

-   `ggplot(summary_data, aes(x = "Max Temp", y = y))`:
    -   We start the plot with `ggplot`, using our `summary_data`.
    -   We set a fixed x-value ("Max Temp") and use our calculated mean for y.
-   `geom_boxplot(...)`:
    -   This creates the boxplot using our summary statistics.
    -   `stat = "identity"` tells ggplot to use our provided values directly.
    -   We set the fill colour to light blue and adjusted the width.
-   `geom_point(...)`:
    -   This adds a red point to represent the median temperature.
-   `ggtitle(...)`:
    -   We give our figure a descriptive title.
    -   **Always do this!** It helps others (and future you) understand the plot.
-   `ylab(...)` and `xlab("")`:
    -   We label the y-axis with the variable name and units.
    -   We leave the x-axis label blank as we only have one category.
    -   **Always label your axes!** It's crucial for interpretation and accessibility.
-   `theme_minimal()`:
    -   This applies a clean, minimal theme to our plot.

This approach gives us a representative boxplot without needing the full dataset, which is great for quick visualisations or when working with large datasets.

Want to modify this plot? Try changing the colours, adding more points, or adjusting the theme. For example, you could add a point for the mean:

```{r, eval=FALSE}
geom_point(aes(y = mean_tasmax), color = "blue", size = 3, shape = "diamond")
```

> üí° **Pro Tip:** Check out this [ggplot cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf). Save it somewhere handy and refer to it often!

Remember, the grammar of graphics is great for goofballs like us! With a few tweaks, you can create all sorts of unique visualisations. Keep practising, and soon you'll be a ggplot pro!

## Workshop: Data Visualization and Basic Statistics

### Testing your knowledge

Before we start coding, let's test your knowledge of R and some basic commands with some multiple-choice questions:

```{r q_variables, echo=FALSE}
question("What symbol is used to store a variable in R?",
         answer("="),
         answer("==="),
         answer("<<<"),
         answer("<-", correct = TRUE),
         random_answer_order = TRUE)
```

```{r q_dataframes, echo=FALSE}
question("What do we call variables that store datasets in R?",
         answer("Arrays"),
         answer("Boxes"),
         answer("Vectors"),
         answer("Data frames", correct = TRUE),
         random_answer_order = TRUE)
```

```{r q_tasmin, echo=FALSE}
question("What type of data is stored in the tasmin variable?",
         answer("Tasmanian miniatures"),
         answer("Minimum atmospheric temperature in the troposphere"),
         answer("Minimum measured near-surface air temperature", correct = TRUE),
         random_answer_order = TRUE)
```

```{r q_stats, echo=FALSE}
question("What command would store the standard deviation of precipitation (pr) in a data frame called hobart_climate?",
         answer("sd_pr = STDDEV(hobart_climate)"),
         answer("sd_pr <- stddev(hobart_climate(pr))"),
         answer("sd_pr <- hobart_climate[pr].sd()"),
         answer("sd_pr <- sd(hobart_climate$pr)", correct = TRUE),
         random_answer_order = TRUE)
```

```{r q_plot, echo=FALSE}
question("What command would create a violin plot using ggplot? Hint: We didn't show this type of plot in the introduction, but there's a cheat sheet you can check to find the right answer!",
         answer("violin_plot()"),
         answer("vplot()"),
         answer("ggplot + violin"),
         answer("geom_violin())", correct = TRUE),
         random_answer_order = TRUE)
```

Great job! If you struggled with these questions, I highly suggest you reread the introduction. It will take some time to build up your R knowledge, but repeated exposure is the best way to get there! Don't forget that the internet is packed with useful resources in addition to the content we provide, including very helpful YouTube videos and free textbooks. The more you explore, the more comfortable you will get with R!

### Now we code!

Now, it's finally time for you to code from scratch! You've got this. Remember, you can ask for help in the workshops or through MyLo. Remember, assessment task 2 is associated with these workshops. Consider how the work you do here can feed into your reports.

> üî• **Important:** You cannot save your work on this webpage. If you create something you want to keep, save it to your computer!

#### Data wrangling

You will need a region to focus on for your workshop portfolio, and data from that region. We have four options:

1.  Monsoonal North, Queensland
2.  East Coast, New South Wales and Queensland
3.  Murray Basin, Victoria and South Australia
4.  Southern Slopes, Tasmania

The choice of location is completely up to you. Consider researching the news and history of each region to inform your final choice. **You cannot pick the Barossa Valley!** We use the Barossa Valley as an example data set, not for the reports.

We can use the function [`list.files`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/list.files) to see the data we have available in this workshop. `list.files` works like many of the functions we used in the introduction. We want to see the data available in the `data` folder, so that folder will be the input for the `list.files` function as a string. Try using the function from scratch here:

```{r list_files-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r list_files, exercise=TRUE, excercise.setup="list_files-setup"}
# Use list.files() to find the data to use in this workshop.
```

```{r list_files-hint-1}
list.files("...")
```

```{r list_files-hint-2}
list.files("./data")
```

```{r list_files-check}
# Intentionally blank.
```


> üí° **Pro tip:** Click the "Hint" button if you're ever stuck, or click "Start Over" to start from scratch.

We can see a data file is available for each region and one for the Barossa Valley that we used in the introduction. Try loading one of these data sets and checking its structure here.

```{r load_data_ex-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r load_data_ex, exercise=TRUE}
# Read in a CSV file from the list chosen above.
```

```{r load_data_ex-hint-1}
read.csv()
```

```{r load_data_ex-hint-2}
read.csv("data/")
```

```{r load_data_ex-check}
# Intentionally blank.
```

The dataset you have loaded is now ready for analysis, as we did in the introduction. In the next code section, calculate the mean, median, and standard deviation of maximum and minimum daily temperature, and precipitation. Use `cat` to print these results together as output from the code box.

```{r basic_stats-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r basic_stats, exercise=TRUE, excercise.setup="list_files-setup"}
# Calculate and print some basic statistics for your data set.
```

```{r basic_stats-hint-1}
mean()
median()
sd()
```

```{r basic_stats-hint-2}
mean(..., na.rm = TRUE)
```

```{r basic_stats-hint-3}
cat("Mean:", ..., "\n")
```

```{r basic_stats-check}
# Intentionally blank.
```

> üîé **Questions to consider for your report**: Use the answers to these questions as the formative thinking for your report. Don't rely on them. Think for yourself!
>
> -   Can we infer anything from these initial statistics?
> -   Could we do something differently to increase the amount of information we receive from these basic statistics?

Now, we should create some visualisations of our data. In the introduction, we created box plots. Box plots are interesting but are not the best we can do to visualise this data. Even changing to a violin plot or overlaying a jittered strip plot can be an easy improvement. In the next exercise, you will create a histogram for each variable. Remember to use the [ggplot cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf) to find the right function to fit the grammar of graphics. Google is your friend! Does a histogram provide insight that is different from the boxplot? Are there other histograms that could be made to visualise aspects of the data?

```{r plot_histogram-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r plot_histogram, exercise=TRUE, excercise.setup="list_files-setup"}
# Plot a labelled and titled histogram of a variable in your data set. 
```

```{r plot_histogram-hint-1}
geom_histogram(binwidth = 1)
```

```{r plot_histogram-hint-2}
ggplot(..., aes(x=...)) +
  geom_histogram()
```

```{r plot_histogram-check}
# Intentionally blank.
```

Through these different plots we are beginning to build up a picture of the climate of your chosen region. So far, we've used the simple inferential statistics of mean, median, and standard deviation. As we go on, we will start using more complicated statistics. One measure of interest is **anomalies**, how much a measurement deviates from the mean. We can calculate an anomaly by applying a calculation across a column in a data frame. For example, for a data frame `df` with column `temp` that has mean stored in `mean_temp`, we can calculate the anomaly for each `temp` measurement and store it in the data frame with `df$temp_anomaly <- df$temp - mean_temp`. Using this formula, calculate the anomalies for your variables in the code box below.

```{r calculate_anomaly-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r calculate_anomaly, exercise=TRUE, excercise.setup="list_files-setup"}
# Calculate the anomalies of variables in your data set.
```

```{r calculate_anomaly-check}
# Intentionally blank.
```

Now, try using some of the plots we have learned so far to visualise the anomaly.

```{r plot_anomaly-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r plot_anomaly, exercise=TRUE, excercise.setup="list_files"}
# Visualise the anomaly of your variables.
```

```{r plot_anomaly-hint-1}
# Try geom_histogram!
```

```{r plot_anomaly-check}
# Intentionally blank.
```

> üîé **Questions to consider for your report**:
>
> -   How would you identify heatwaves in the provided data? What about droughts?
> -   What background knowledge can you collect about your region to inform your statistical analysis?

We've reached the end. Great job on making it through our first R workshops for KGA320. This has been a big first step; we still have a lot of ground to cover, but now that we've introduced the basics, things will get easier! Remember that we're here to help; there's a wealth of resources available, and take the time to build up an understanding of the parts of this workshop you may have found tricky. We have one last exercise, to lead into next week.

So far, our plots have completely ignored a key aspect of our data - the progression of time. The study of climate revolves around how Earth's systems change over time, so we need to learn how to conduct **time-series analysis**. In the following exercise box, try building a plot with time on the x-axis and one of the available variables on the y-axis. Try using `geom_point`!

```{r time_series-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r time_series, exercise=TRUE, excercise.setup="list_files-setup"}
# Create a time series plot.
```

```{r time_series-check}
# Intentionally blank.
```

```{r time_series-hint-1}
# An example using barossa_data
ggplot(barossa_data, aes(x = time, y = tasmax)) +  # Specify the data and mapping of aesthetics
  geom_point() +  # Add a line plot layer
  ggtitle("trend of maximum temperature (1951-2014)") +  # add a title to the plot
  xlab("Year") +  # Label the x-axis
  ylab("maximum temperature (¬∞c)")  # label the y-axis
```

If you've done things right, this plot will look... uninformative. It will be very noisy, and not show any clear trends. How could we improve this? Find out next week!

### Playground

If you have extra time, or want to build on the work you've done so far, use the code box below.

```{r playground-setup}
list2env(as.list(work_env, all.names = TRUE), envir = environment())
```

```{r playground, exercise=TRUE, excercise.setup="list_files-setup"}

```

```{r playground-check}
# Intentionally blank.
```
